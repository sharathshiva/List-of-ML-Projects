{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Analyzer using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371731306c3e504b191979706e826c247def88dc"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import keras\n",
    "#from keras import backend as K\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086162161ba405b800863e7d545b5917e5205984"
   },
   "source": [
    "### Create the directory structure\n",
    "\n",
    "In these folders we will store the images that will later be fed to the Keras generators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d24ef21f9f2359b8bf6b3e7a0b8ab5a43daaf566"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create 7 folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    " \n",
    "# val_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "nv = os.path.join(train_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(train_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(train_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(train_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(train_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(train_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(train_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "nv = os.path.join(val_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(val_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(val_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(val_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(val_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(val_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(val_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ae8d37fdee293aaffa71a79019dd7277f8288fc"
   },
   "source": [
    "### Create Train and Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "268503398ef61904e05a2c0b0667d589f08a19a8"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('../input/HAM10000_metadata.csv')\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c46ea5967e095d31dcf144b6f57f0343878fa432"
   },
   "source": [
    "### Create a stratified val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53e4b7b152ed831a7d7516156ac300c0e6985ffc"
   },
   "outputs": [],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df = df_data.groupby('lesion_id').count()\n",
    "\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df = df[df['image_id'] == 1]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24720fe3ea9f2f4b571abd09ecfbb931d6429852"
   },
   "outputs": [],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only\n",
    "# one image.\n",
    "\n",
    "def identify_duplicates(x):\n",
    "    \n",
    "    unique_list = list(df['lesion_id'])\n",
    "    \n",
    "    if x in unique_list:\n",
    "        return 'no_duplicates'\n",
    "    else:\n",
    "        return 'has_duplicates'\n",
    "    \n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_data['duplicates'] = df_data['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08b7eef3e0ac4112f63b8fb26ce19d55483cbc04"
   },
   "outputs": [],
   "source": [
    "df_data['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "995445dfda2745165a53e61f42615104b951d4af"
   },
   "outputs": [],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39fde25b59a9452cf700c5b2ff82cc7cc45c4a33"
   },
   "outputs": [],
   "source": [
    "# now we create a val set using df because we are sure that none of these images\n",
    "# have augmented duplicates in the train set\n",
    "y = df['dx']\n",
    "\n",
    "_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\n",
    "\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df37227f7ce993d054ed5b8480ee724696fc210"
   },
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08c5e12fcef2da5f49267a6b82161b2c52c2b20a"
   },
   "source": [
    "### Create a train set that excludes images that are in the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03715a6cf5aeb6430ee144a84eb10dde216c0fb9"
   },
   "outputs": [],
   "source": [
    "# This set will be df_data excluding all rows that are in the val set\n",
    "\n",
    "# This function identifies if an image is part of the train\n",
    "# or val set.\n",
    "def identify_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    \n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_data['train_or_val'] = df_data['image_id']\n",
    "# apply the function to this new column\n",
    "df_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n",
    "   \n",
    "# filter out train rows\n",
    "df_train = df_data[df_data['train_or_val'] == 'train']\n",
    "\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b976a9018b1bd2dc0522c68339c5861534a1571"
   },
   "outputs": [],
   "source": [
    "df_train['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1581d5a3e86f9673ae175102112017e30229bc37"
   },
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8812ad87c4fa18d2d82497df42c3895c7f10bc39"
   },
   "source": [
    "### Transfer the Images into the Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4acee2b7879762e50b52df118a9b691515fe7ac0"
   },
   "outputs": [],
   "source": [
    "# Set the image_id as the index in df_data\n",
    "df_data.set_index('image_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eca02fbf066c8124d0cb465295bbd2593f5f045a"
   },
   "outputs": [],
   "source": [
    "# Get a list of images in each of the two folders\n",
    "folder_1 = os.listdir('../input/ham10000_images_part_1')\n",
    "folder_2 = os.listdir('../input/ham10000_images_part_2')\n",
    "\n",
    "# Get a list of train and val images\n",
    "train_list = list(df_train['image_id'])\n",
    "val_list = list(df_val['image_id'])\n",
    "\n",
    "\n",
    "\n",
    "# Transfer the train images\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    fname = image + '.jpg'\n",
    "    label = df_data.loc[image,'dx']\n",
    "    \n",
    "    if fname in folder_1:\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/ham10000_images_part_1', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/ham10000_images_part_2', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "# Transfer the val images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "    fname = image + '.jpg'\n",
    "    label = df_data.loc[image,'dx']\n",
    "    \n",
    "    if fname in folder_1:\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/ham10000_images_part_1', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        # source path to image\n",
    "        src = os.path.join('../input/ham10000_images_part_2', fname)\n",
    "        # destination path to image\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "        # copy the image from the source to the destination\n",
    "        shutil.copyfile(src, dst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a4847c4cc799c23e57bf2531d92117cb95e1b07"
   },
   "outputs": [],
   "source": [
    "# check how many train images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd05c08cbfa00418dc333f5b67d1ff6e98aa973e"
   },
   "outputs": [],
   "source": [
    "# check how many val images we have in each folder\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cebcb5242ff542efb03be5086bf3796bea70c591"
   },
   "source": [
    "### Copy the train images  into aug_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fe970d74e9d5a284420af4ad37d8aae89dc1c15"
   },
   "outputs": [],
   "source": [
    "# note that we are not augmenting class 'nv'\n",
    "class_list = ['mel','bkl','bcc','akiec','vasc','df']\n",
    "\n",
    "for item in class_list:\n",
    "    \n",
    "    # We are creating temporary directories here because we delete these directories later\n",
    "    # create a base dir\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    # create a dir within the base dir to store images of the same class\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "\n",
    "    # Choose a class\n",
    "    img_class = item\n",
    "\n",
    "    # list all images in that directory\n",
    "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
    "\n",
    "    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n",
    "    for fname in img_list:\n",
    "            # source path to image\n",
    "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
    "            # destination path to image\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            # copy the image from the source to the destination\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "    # point to a dir containing the images and not to the images themselves\n",
    "    path = aug_dir\n",
    "    save_path = 'base_dir/train_dir/' + img_class\n",
    "\n",
    "    # Create a data generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        #brightness_range=(0.9,1.1),\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                           save_to_dir=save_path,\n",
    "                                           save_format='jpg',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    # Generate the augmented images and add them to the training folders\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_aug_images_wanted = 6000 # total number of images we want to have in each class\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
    "\n",
    "    # run the generator and create about 6000 augmented images\n",
    "    for i in range(0,num_batches):\n",
    "\n",
    "        imgs, labels = next(aug_datagen)\n",
    "        \n",
    "    # delete temporary directory with the raw image files\n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9bbc56bd25441150d2430dca2b07d8ebae57d95"
   },
   "outputs": [],
   "source": [
    "# Check how many train images we now have in each folder.\n",
    "# This is the original images plus the augmented images.\n",
    "\n",
    "print(len(os.listdir('base_dir/train_dir/nv')))\n",
    "print(len(os.listdir('base_dir/train_dir/mel')))\n",
    "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/train_dir/df')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21de03bdc63ecf78cc061d364d14d3216a544b43"
   },
   "outputs": [],
   "source": [
    "# Check how many val images we have in each folder.\n",
    "\n",
    "print(len(os.listdir('base_dir/val_dir/nv')))\n",
    "print(len(os.listdir('base_dir/val_dir/mel')))\n",
    "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
    "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
    "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
    "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
    "print(len(os.listdir('base_dir/val_dir/df')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "767cb7d35e301369f020cdbb705da1620ba8e594"
   },
   "source": [
    "### Visualize 50 augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f0e13a8455af926fe449e1b3ea818b704724202"
   },
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "        \n",
    "plots(imgs, titles=None) # titles=labels will display the image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3e2126a39c06568a1f95da2ab42353447d1be20"
   },
   "outputs": [],
   "source": [
    "# End of Data Preparation\n",
    "### ===================================================================================== ###\n",
    "# Start of Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32dad10b7c104d2baa972da8cbadc7d6038af05c"
   },
   "source": [
    "### Set Up the Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa1041d69b0e8313324b91e3e9475799e1ad61c2"
   },
   "outputs": [],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0e5aede7139196b0d4e1344b278e7621f005550"
   },
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "    tensorflow.keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "train_batches = datagen.flow_from_directory(train_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=train_batch_size)\n",
    "\n",
    "valid_batches = datagen.flow_from_directory(valid_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=val_batch_size)\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_batches = datagen.flow_from_directory(valid_path,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ee4ee41f1b16083bd9fc20ee9dec40acccc97dd"
   },
   "source": [
    "### Modify MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad582cb8ea0ca2d563fc367aa89b7edfafc1a57f"
   },
   "outputs": [],
   "source": [
    "# create a copy of a mobilenet model\n",
    "\n",
    "mobile = tensorflow.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "960449ec7ecdda92ba733ad23b00b7be605f3d4b"
   },
   "outputs": [],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b7922bdf625675834d9b63ec0e85351bd9f3c0f"
   },
   "outputs": [],
   "source": [
    "type(mobile.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f832e5865c65a013a06dbf5d500c0381020c56d5"
   },
   "outputs": [],
   "source": [
    "# How many layers does MobileNet have?\n",
    "len(mobile.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4dd9dcf26d85a57a113e6b158cf8fceeca7f99de"
   },
   "outputs": [],
   "source": [
    "# CREATE THE MODEL ARCHITECTURE\n",
    "\n",
    "# Exclude the last 5 layers of the above model.\n",
    "# This will include all layers up to and including global_average_pooling2d_1\n",
    "x = mobile.layers[-6].output\n",
    "\n",
    "# Create a new dense layer for predictions\n",
    "# 7 corresponds to the number of classes\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "# inputs=mobile.input selects the input layer, outputs=predictions refers to the\n",
    "# dense layer we created above.\n",
    "\n",
    "model = Model(inputs=mobile.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b38734b72afc4289ab187a9e683cbda6bf3269bc"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9d74e44630c3d07a596460c8fbfda3ae7cae1e9"
   },
   "outputs": [],
   "source": [
    "# We need to choose how many layers we actually want to be trained.\n",
    "\n",
    "# Here we are freezing the weights of all layers except the\n",
    "# last 23 layers in the new model.\n",
    "# The last 23 layers of the model will be trained.\n",
    "\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13cf63a53e5195cb8a9725d2506c71108bc478b9"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "915f30a4f5ad369713bcb8e3bfa438219d6c8ef7"
   },
   "outputs": [],
   "source": [
    "# Define Top2 and Top3 Accuracy\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2013ff1abae70fed845af94e7ab3d95cefad0d61"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n",
    "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62e7a784a33d4c868f49a3ef1f9acbc7186e3338"
   },
   "outputs": [],
   "source": [
    "# Get the labels that are associated with each index\n",
    "print(valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3001857c9a3c2b15c2343627e340eb1ae858fae9"
   },
   "outputs": [],
   "source": [
    "# Add weights to try to make the model more sensitive to melanoma\n",
    "\n",
    "class_weights={\n",
    "    0: 1.0, # akiec\n",
    "    1: 1.0, # bcc\n",
    "    2: 1.0, # bkl\n",
    "    3: 1.0, # df\n",
    "    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n",
    "    5: 1.0, # nv\n",
    "    6: 1.0, # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "4a5e3bc3cf44f1d4326c34ad880a302ba082e9d5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_batches, steps_per_epoch=train_steps, \n",
    "                              class_weight=class_weights,\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=30, verbose=1,\n",
    "                   callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3e43e3f2943db4be9d75831fe23661ae9deb44b"
   },
   "source": [
    "### Evaluate the model using the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "710ee26097924153647ac432c8ade29383fe42f1"
   },
   "outputs": [],
   "source": [
    "# get the metric names so we can use evaulate_generator\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68603a5e8cb5e507db95074a07b552a61fa48e11"
   },
   "outputs": [],
   "source": [
    "# Here the the last epoch will be used.\n",
    "\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate_generator(test_batches, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897f066da922d81fefa165a6b911a741c52ef7f5"
   },
   "outputs": [],
   "source": [
    "# Here the best epoch will be used.\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate_generator(test_batches, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3fffba5e0aa9088cda1865c7b8d75d72c20d0f6"
   },
   "source": [
    "### Plot the Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cbd11ef4286a751ef2918361af035d356f341ae"
   },
   "outputs": [],
   "source": [
    "# display the loss and accuracy curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_top2_acc = history.history['top_2_accuracy']\n",
    "val_top2_acc = history.history['val_top_2_accuracy']\n",
    "train_top3_acc = history.history['top_3_accuracy']\n",
    "val_top3_acc = history.history['val_top_3_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training cat acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation cat acc')\n",
    "plt.title('Training and validation cat accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\n",
    "plt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\n",
    "plt.title('Training and validation top2 accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\n",
    "plt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\n",
    "plt.title('Training and validation top3 accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4204e4056c8d12c1fee72b97912879cad4ee483f"
   },
   "source": [
    "### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74a66905f7a2d702f3d2aad9abf9fe114b96f0ff"
   },
   "outputs": [],
   "source": [
    "# Get the labels of the test images.\n",
    "\n",
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "53f4b22617285e923f336cdb2ffcbe1f9ff5e5db"
   },
   "outputs": [],
   "source": [
    "# We need these to plot the confusion matrix.\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5113e039e8384b96595751e084f0c5ed677080a"
   },
   "outputs": [],
   "source": [
    "# Print the label associated with each class\n",
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "701dafc5874aa60a054a74c04170cb7e8d750e94"
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "predictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcce17ac0488ff90d29b11592c9226ed1bb210fb"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cfd9bdbbd27e27d9c5de7c6593527686445ea89"
   },
   "outputs": [],
   "source": [
    "# Source: Scikit Learn website\n",
    "# http://scikit-learn.org/stable/auto_examples/\n",
    "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
    "# selection-plot-confusion-matrix-py\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d499136cdb5fdf356515beb6e0cd1130ed584db"
   },
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "940b71bb2b37d847ba81dd67ca50c7fd5785fd35"
   },
   "outputs": [],
   "source": [
    "# argmax returns the index of the max value in a row\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97c6b493c368ff6565782c1bb15827f5d349ef79"
   },
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ddbd33a93468075c64ba49188a6d272a5c7828f"
   },
   "outputs": [],
   "source": [
    "# Define the labels of the class indices. These need to match the \n",
    "# order shown above.\n",
    "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "571f3f23d58daa03ec3fbf9207363063b2a63373"
   },
   "source": [
    "### Generate the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebc31a49c8e8ab5d1305e46a7d638e0da326da8b"
   },
   "outputs": [],
   "source": [
    "# Get the index of the class with the highest probability score\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the labels of the test images.\n",
    "y_true = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05027fe3475ab922340f9d905ec1239e2157fa05"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8313f0f4024fdb8053f943136880e63ac962ac2"
   },
   "source": [
    "**Recall** = Given a class, will the classifier be able to detect it?<br>\n",
    "**Precision** = Given a class prediction from a classifier, how likely is it to be correct?<br>\n",
    "**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c46f3f1d257241f96b4aac7eb96831ff8bbea33"
   },
   "outputs": [],
   "source": [
    "# End of Model Building\n",
    "### ===================================================================================== ###\n",
    "# Convert the Model from Keras to Tensorflow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7df391a2792ddfb7fa2a980776aeac744612f702"
   },
   "outputs": [],
   "source": [
    "# check the the directory containing the model is available\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71dd9a6a021d4ffcc159dafd52e7f86ecc6558cb"
   },
   "outputs": [],
   "source": [
    "# view the files that make up the tensorflow.js model\n",
    "#os.listdir('tfjs_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f774cd15c6de188d4bb150f25ab600e5cbc06031"
   },
   "outputs": [],
   "source": [
    "# Delete the image data directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffb96375ce44ef009192bf6ddb44f6eb53a43838"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
